Slide 2: Motivation
	â€¢	Problem: Hallucinations in LLMs undermine trust in generative NLP
	â€¢	Challenge: Existing methods are piecemeal â€” they detect either factual errors or entailment issues, not both
	â€¢	Goal: Build a comprehensive system that detects all hallucination types (factual, contradictory, misleading, omitted)

Visual:
Diagram showing three overlapping circles: Factual Consistency, Entailment, Semantic Similarity â†’ hallucination detection in the center

â¸»

ğŸš¨ Slide 3: Hallucination Types (Taxonomy)
	â€¢	Factual Error: Wrong numbers, names, dates
	â€¢	Contradiction: Opposes known or stated information
	â€¢	Omission: Leaves out critical facts
	â€¢	Misleading/Fabrication: Uses same entities with unrelated facts

Visual: Table or icons showing each type with examples


ğŸ” Slide 5: Core Modules

Break down the 3 detection modules:
	â€¢	Semantic Similarity
	â€¢	Embeddings + TF-IDF + Word Overlap
	â€¢	Factual Consistency
	â€¢	Named entities, numbers, money, dates, actions
	â€¢	Entailment
	â€¢	Bidirectional DeBERTa-based NLI

Visual: Table or side-by-side comparison of modules

â¸»

ğŸ§  Slide 6: Classifier Logic

How decisions are made:
	â€¢	High similarity + factual errors â†’ factual hallucination
	â€¢	High similarity + contradictions â†’ contradiction
	â€¢	Low similarity + same entities â†’ misleading
	â€¢	Missing facts â†’ omission

Visual: Flowchart of decision tree or example-based logic map

â¸»

ğŸŒ Slide 7: Graph-Based Framework
	â€¢	Nodes: Paragraphs
	â€¢	Edges: Consistency (semantic + factual)
	â€¢	Metrics:
	â€¢	PageRank â†’ importance
	â€¢	Centrality â†’ coherence
	â€¢	Isolation â†’ hallucination risk

Visual: Sample graph with colored nodes (consistent vs. hallucinated)

â¸»

ğŸ“Š Slide 8: Scoring Metrics

Show the final scores:
	â€¢	Factual Accuracy
	â€¢	Logical Consistency
	â€¢	Semantic Coherence
	â€¢	Information Completeness
	â€¢	Overall Reliability (weighted)

Visual: Radar chart or stacked bar chart

â¸»

ğŸ“ Slide 9: Visualization Demo

Embed screenshots or link to interactive visualization:
	â€¢	D3-based HTML graph
	â€¢	Tooltip with paragraph-level analysis
	â€¢	Color legend for hallucination types

Optional: Short video demo or gif

â¸»

ğŸ§ª Slide 10: Example Results


table


Slide 11: Why This Matters
	â€¢	Unified approach: no need for separate tools for fact-checking, NLI, or semantic match
	â€¢	Scalable, modular, explainable
	â€¢	Applicable to summarization, QA, dialogue, RAG systems

Visual: Application icons or domains (chatbots, news gen, etc.)

â¸»

ğŸ› ï¸ Slide 12: Future Work
	â€¢	Integrate retrieval grounding (RAG context)
	â€¢	Extend to multimodal (text + image)
	â€¢	Automate feedback loop for self-correction in generation

â¸»

ğŸ“¬ Slide 13: Thank You / Q&A
	â€¢	Contact Info
	â€¢	GitHub / Live Demo Link (if available)