Category
Description
Example
Dates
Absolute or relative temporal mentions
â€œJanuary 15, 2024â€, â€œQ4 2023â€
Money
Currency strings, normalized to floats
â€œ$2.5Mâ€ â†’ 2_500_000.0
Percentages
% expressions
â€œ15%â€
Named Entities
People, organizations, locations (via NLTK NE)
â€œJohn Smithâ€ â†’ PERSON
Actions
Verb-object phrases
â€œannounced expansionâ€
Claims
Sentences with quantitative info
â€œRevenue was $2.5M in Q4 2023â€


next slide
Method
What It Measures
Tool Used
Sentence Embeddings
Deep contextual similarity
all-MiniLM-L6-v2 via SentenceTransformers
TF-IDF Cosine
Lexical co-occurrence across n-grams
Scikit-learn TfidfVectorizer
Word Overlap (Jaccard)
Token-level intersection over union
NLTK tokenization

Embeddings capture meaning but miss rare tokens
	â€¢	TF-IDF highlights shared terms but ignores semantics
	â€¢	Jaccard adds interpretable coverage metric

â†’ Hybrid approach = more robust detection


Side-by-side or stacked bar chart comparing:
	â€¢	Embedding score
	â€¢	TF-IDF similarity
	â€¢	Jaccard overlap
	â€¢	Final combined score

Maybe with 2 example paragraph pairs:
	â€¢	One consistent
	â€¢	One semantically distant

â¸»

ğŸ§  Speaker Notes:
	â€¢	â€œSemantic similarity doesnâ€™t tell you whether a claim is true â€” but it tells you whether itâ€™s relevant.â€
	â€¢	â€œWe only consider hallucination if the candidate is semantically related to the reference.â€
	â€¢	â€œThis layer filters out off-topic but non-harmful outputs



next slide

how the system detects factual errors, omissions, and contradictions by comparing structured information between the reference and candidate.


Fact Type
Matching Strategy
Example
Money
Normalized value + local context
â€œ$2.5M revenueâ€ vs â€œ$3.2M revenueâ€
Dates
Set overlap
â€œJan 15, 2024â€ missing or changed
Percentages
Set overlap
â€œ15%â€ vs â€œ20%â€
Numbers
Numerical proximity and relevance
â€œQ4 growth 12%â€ vs â€œQ4 growth 18%â€
Named Entities
Set intersection (PERSON, ORG)
Missing â€œJohn Smithâ€
Actions
Verb-object phrase matching
â€œannounced expansionâ€ vs â€œcut jobsâ€


We donâ€™t just check whether facts exist â€” we check whether they match and occur in the same context.â€
	â€¢	â€œThis layer is key to catching subtle numeric hallucinations, which are the most dangerous in domains like finance or medicine.â€


next slide

Factual matching doesnâ€™t catch semantic opposites
	â€¢	Contradictions occur even if entities/values match

â¸»

ğŸ§  Speaker Notes:
	â€¢	â€œA hallucination can be logically false even when it mentions the same facts.â€
	â€¢	â€œThis NLI step captures semantic conflicts, not just mismatches.â€
	â€¢	â€œWe use contradiction scores to detect hallucinations like â€˜declinedâ€™ vs â€˜increasedâ€™.


next alide

Signal Source
Metric
Semantic Module
Combined similarity score
Factual Module
Overall consistency score
Entailment Module
Contradiction score (max bidir.)




We donâ€™t rely on a black-box model.
Instead, we use thresholded signals from 3 modules and apply logical rules.

We prioritize transparency and explainability.â€
	â€¢	â€œThis logic lets users trace why a hallucination was flagged.â€
	â€¢	â€œWe also calibrate confidence based on multiple factors.â€

next alode

Element
Meaning
Nodes
Paragraphs (1 reference + N candidates)
Edges
Consistency links based on multi-view similarity
Edge Weight
1 âˆ’ average hallucination score between pair
Edge Type
Consistent / Partial Hallucination / Mutual Hallucination


text: actual paragraph
	â€¢	num_facts: number of claims extracted
	â€¢	num_entities: number of named entities
	â€¢	entropy: lexical entropy of the paragraph
	â€¢	classification: hallucination type
	â€¢	PageRank: trustworthiness/centrality score


next slide

Candidate Summary (abridged)
Label
Detected Type
Confidence
Reason
â€œRevenue was $2.5M, up 15%. CEO announced expansion Jan 15.â€
CONSISTENT
â€”
â€”
All facts aligned
â€œRevenue was $3.2M, up 20%. Expansion Jan 20.â€
HALLUCINATED
Factual Error
0.90
Money/date mismatch
â€œRevenue declined in Q4. CEO announced expansion.â€
HALLUCINATED
Contradiction
0.85
Opposite trend vs reference
â€œCompany performed well; CEO optimistic about future growth.â€
HALLUCINATED
Omission
0.75
Key facts missing
â€œRevenue fell to $2.5M. CEO abandoned expansion plans.â€
HALLUCINATED
Fabrication
0.82
Opposite claim, hallucinated event


All major hallucination types are detected accurately
	â€¢	Explanations are human-interpretable
	â€¢	Confidence levels align well with severity

â¸»

ğŸ§  Speaker Notes:
	â€¢	â€œWe benchmarked our system on realistic candidate generations, including subtle and blatant hallucinations.â€
	â€¢	â€œThe classifier not only flags issues â€” it gives actionable insights.â€
	â€¢	â€œThis is especially helpful in LLM evaluation pipelines.â€


